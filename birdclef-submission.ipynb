{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc35d2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:31:46.674809Z",
     "iopub.status.busy": "2023-07-28T16:31:46.673928Z",
     "iopub.status.idle": "2023-07-28T16:31:46.680351Z",
     "shell.execute_reply": "2023-07-28T16:31:46.679079Z"
    },
    "papermill": {
     "duration": 0.022732,
     "end_time": "2023-07-28T16:31:46.685038",
     "exception": false,
     "start_time": "2023-07-28T16:31:46.662306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This file is a modified version of the original:\n",
    "# https://www.kaggle.com/code/honglihang/2nd-place-solution-inference-kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8060320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:31:46.703570Z",
     "iopub.status.busy": "2023-07-28T16:31:46.703120Z",
     "iopub.status.idle": "2023-07-28T16:31:50.805191Z",
     "shell.execute_reply": "2023-07-28T16:31:50.803505Z"
    },
    "papermill": {
     "duration": 4.114772,
     "end_time": "2023-07-28T16:31:50.808027",
     "exception": false,
     "start_time": "2023-07-28T16:31:46.693255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://intel.github.io/intel-extension-for-tensorflow/latest/docs/guide/practice_guide.html\n",
    "\n",
    "# OpenMP* Environment Variable. OpenMP (Open Multi-Processing) is an application programming interface (API) that -\n",
    "# - provides a set of directives and library functions for parallel programming in shared-memory multiprocessing environments. \n",
    "!export OMP_NUM_THREADS=N # N is the number of threads. \n",
    "\n",
    "# determines how OpenMP threads are scheduled.\n",
    "!export OMP_SCHEDULE=STATIC\n",
    "\n",
    "# specifies whether threads may be moved between processors. Setting it to CLOSE keeps OpenMP threads close to - \n",
    "# - the primary thread in contiguous place partitions. \n",
    "!export OMP_PROC_BIND=CLOSE\n",
    "\n",
    "# binds threads to specific CPUs. the variable should contain a space-separated or comma-separated list of CPUs - \n",
    "# -or hyphen-separated CPU numbers specifying a range of CPUs.\n",
    "!export GOMP_CPU_AFFINITY=\"N-M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c728a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:31:50.826322Z",
     "iopub.status.busy": "2023-07-28T16:31:50.825882Z",
     "iopub.status.idle": "2023-07-28T16:32:04.818826Z",
     "shell.execute_reply": "2023-07-28T16:32:04.817551Z"
    },
    "papermill": {
     "duration": 14.005677,
     "end_time": "2023-07-28T16:32:04.821880",
     "exception": false,
     "start_time": "2023-07-28T16:31:50.816203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/openvino-wheels\r\n",
      "Processing /kaggle/input/openvino-wheels/openvino-2022.3.0-9052-cp37-cp37m-manylinux_2_17_x86_64.whl\r\n",
      "Requirement already satisfied: numpy<=1.23.4,>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from openvino==2022.3.0) (1.21.6)\r\n",
      "Installing collected packages: openvino\r\n",
      "Successfully installed openvino-2022.3.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/openvino-wheels/openvino-2022.3.0-9052-cp37-cp37m-manylinux_2_17_x86_64.whl --no-index --find-links /kaggle/input/openvino-wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "768cedb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:04.841811Z",
     "iopub.status.busy": "2023-07-28T16:32:04.841327Z",
     "iopub.status.idle": "2023-07-28T16:32:10.117479Z",
     "shell.execute_reply": "2023-07-28T16:32:10.115879Z"
    },
    "papermill": {
     "duration": 5.290151,
     "end_time": "2023-07-28T16:32:10.120740",
     "exception": false,
     "start_time": "2023-07-28T16:32:04.830589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import torch\n",
    "import gc\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import librosa as lb\n",
    "import soundfile as sf\n",
    "from  soundfile import SoundFile \n",
    "import torchaudio\n",
    "\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions import Beta\n",
    "from torch.nn.parameter import Parameter\n",
    "from joblib.externals.loky.backend.context import get_context\n",
    "#torch.jit.enable_onednn_fusion(True)\n",
    "\n",
    "import openvino.runtime as ov\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f5e1b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:10.141050Z",
     "iopub.status.busy": "2023-07-28T16:32:10.140584Z",
     "iopub.status.idle": "2023-07-28T16:32:10.148993Z",
     "shell.execute_reply": "2023-07-28T16:32:10.147955Z"
    },
    "papermill": {
     "duration": 0.021971,
     "end_time": "2023-07-28T16:32:10.151249",
     "exception": false,
     "start_time": "2023-07-28T16:32:10.129278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    num_classes = 264\n",
    " \n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
    "\n",
    "    data_root = \"/kaggle/input/birdclef-2023/\"\n",
    "    train_path = \"/kaggle/input/bc2023-train-val-df/train.csv\"\n",
    "    valid_path = \"/kaggle/input/bc2023-train-val-df/valid.csv\"\n",
    "    \n",
    "    train_path = \"/kaggle/input/bc2023-train-val-df/train.csv\"\n",
    "    valid_path = \"/kaggle/input/bc2023-train-val-df/valid.csv\"\n",
    "    test_path = '/kaggle/input/birdclef-2023/test_soundscapes/'\n",
    "\n",
    "    SR = 32000\n",
    "    DURATION = 5\n",
    "    \n",
    "    infer_duration=5\n",
    "    \n",
    "    train_duration=10\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Sed model\n",
    "    model_ckpt = [\n",
    "        '/kaggle/input/birdclef-weights/birdclef-weights/sed_v2s_final_finetune/sed.xml', #v2s\n",
    "        '/kaggle/input/birdclef-weights/birdclef-weights/sed_b3ns_finetune/sed.xml', #b3ns\n",
    "    ]\n",
    "    \n",
    "    # CNN model\n",
    "    re_model_ckpt = [\n",
    "        '/kaggle/input/birdclef-weights/birdclef-weights/re_b3ns_ce/re.xml', #b3ns\n",
    "        '/kaggle/input/birdclef-weights/birdclef-weights/re_v2s_finetune/re.xml', #v2s\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a00806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:10.171670Z",
     "iopub.status.busy": "2023-07-28T16:32:10.171181Z",
     "iopub.status.idle": "2023-07-28T16:32:10.327882Z",
     "shell.execute_reply": "2023-07-28T16:32:10.326651Z"
    },
    "papermill": {
     "duration": 0.170304,
     "end_time": "2023-07-28T16:32:10.330869",
     "exception": false,
     "start_time": "2023-07-28T16:32:10.160565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(Config.train_path)\n",
    "# Config.num_classes = len(df_train.primary_label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "885f80dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:10.349617Z",
     "iopub.status.busy": "2023-07-28T16:32:10.348825Z",
     "iopub.status.idle": "2023-07-28T16:32:10.356993Z",
     "shell.execute_reply": "2023-07-28T16:32:10.356148Z"
    },
    "papermill": {
     "duration": 0.019953,
     "end_time": "2023-07-28T16:32:10.359154",
     "exception": false,
     "start_time": "2023-07-28T16:32:10.339201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef sigmoid(a):\\n    return 1 / (1 + np.exp(-a))\\ndef odds(p):\\n    return p / (1 - p)\\ndef logit(p):\\n    return np.log(odds(p))\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def sigmoid(a):\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "def odds(p):\n",
    "    return p / (1 - p)\n",
    "def logit(p):\n",
    "    return np.log(odds(p))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06512500",
   "metadata": {
    "papermill": {
     "duration": 0.008094,
     "end_time": "2023-07-28T16:32:10.376705",
     "exception": false,
     "start_time": "2023-07-28T16:32:10.368611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fca650c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:10.395799Z",
     "iopub.status.busy": "2023-07-28T16:32:10.395352Z",
     "iopub.status.idle": "2023-07-28T16:32:10.454089Z",
     "shell.execute_reply": "2023-07-28T16:32:10.452913Z"
    },
    "papermill": {
     "duration": 0.071799,
     "end_time": "2023-07-28T16:32:10.456828",
     "exception": false,
     "start_time": "2023-07-28T16:32:10.385029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pred(df_test,num_workers=1,sleep=0,batch_size=1):    \n",
    "    core = ov.Core()    \n",
    "\n",
    "    class BirdDatasetSED(torch.utils.data.Dataset):\n",
    "\n",
    "        def __init__(self, df, sr = Config.SR,n_mels=128, fmin=0, fmax=None, step=None, res_type=\"kaiser_fast\",resample=True, duration = Config.DURATION, train = True):\n",
    "\n",
    "            self.df = df\n",
    "            self.sr = sr \n",
    "            self.n_mels = n_mels\n",
    "            self.fmin = fmin\n",
    "            self.fmax = fmax or self.sr//2\n",
    "\n",
    "            self.train = train\n",
    "            self.duration = duration\n",
    "\n",
    "            self.audio_length = self.duration*self.sr\n",
    "            self.step = step or self.audio_length\n",
    "\n",
    "            self.res_type = res_type\n",
    "            self.resample = resample   \n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.df)\n",
    "\n",
    "        def read_file(self, filepath):\n",
    "            #audio, orig_sr = torchaudio.load(filepath)\n",
    "            #if orig_sr != self.sr:\n",
    "            #    # sinc_interpolation\n",
    "            #    resample_transform = torchaudio.transforms.Resample(orig_sr, self.sr, resampling_method=\"kaiser_window\")\n",
    "            #    audio = resample_transform(audio)\n",
    "\n",
    "            audio, orig_sr = sf.read(filepath, dtype=\"float32\")\n",
    "\n",
    "            if self.resample and orig_sr != self.sr:\n",
    "                audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n",
    "\n",
    "            seconds = []\n",
    "            for i in range(self.audio_length, len(audio) + self.step, self.step):\n",
    "                start = max(0, i - self.audio_length)\n",
    "                end = start + self.audio_length\n",
    "                if end > len(audio):\n",
    "                    pass\n",
    "                else:\n",
    "                    seconds.append(int(end/self.sr))\n",
    "\n",
    "            audio = np.concatenate([audio,audio,audio])\n",
    "            audios = []\n",
    "            for i,second in enumerate(seconds):\n",
    "                end_seconds = int(second)\n",
    "                start_seconds = int(end_seconds - Config.DURATION)\n",
    "\n",
    "                end_index = int(self.sr * (end_seconds + (Config.train_duration - Config.DURATION) / 2) ) + len(audio) // 3\n",
    "                start_index = int(self.sr * (start_seconds - (Config.train_duration - Config.DURATION) / 2) ) + len(audio) // 3\n",
    "                end_pad = int(self.sr * (Config.train_duration - Config.DURATION) / 2) \n",
    "                start_pad = int(self.sr * (Config.train_duration - Config.DURATION) / 2) \n",
    "                y = audio[start_index:end_index].astype(np.float32)\n",
    "                \n",
    "                if i==0:\n",
    "                    y[:start_pad] = 0\n",
    "                elif i==(len(seconds)-1):\n",
    "                    y[-end_pad:] = 0\n",
    "                audios.append(y)\n",
    "                \n",
    "            audios = np.stack(audios)\n",
    "            audios = torch.tensor(audios).float().unsqueeze(1)\n",
    "            spec384,spec256,spec300_another,spec_rev2s=transform_to_spec(audios,train=False)\n",
    "            return spec384,spec256,spec300_another,spec_rev2s\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "\n",
    "            return self.read_file(self.df.loc[idx, \"path\"])\n",
    "        \n",
    "\n",
    "    hop_length384 = Config.infer_duration*Config.SR // (384-1)\n",
    "    melspec_transform = torchaudio.transforms.MelSpectrogram(sample_rate=Config.SR, hop_length=hop_length384, n_mels=128, f_min=0, f_max=Config.SR//2, n_fft=2048, center=True, pad_mode='constant',norm='slaney',onesided=True,mel_scale='slaney')\n",
    "    hop_length256 = Config.infer_duration*Config.SR // (256-1)\n",
    "    melspec_transform256 = torchaudio.transforms.MelSpectrogram(sample_rate=Config.SR, hop_length=hop_length256, n_mels=128, f_min=0, f_max=Config.SR//2, n_fft=2048, center=True, pad_mode='constant',norm='slaney',onesided=True,mel_scale='slaney')\n",
    "    #hop_length224 = Config.infer_duration*Config.SR // (224-1)\n",
    "    #melspec_transform224 = torchaudio.transforms.MelSpectrogram(sample_rate=Config.SR, hop_length=hop_length224, n_mels=128, f_min=0, f_max=Config.SR//2, n_fft=2048, center=True, pad_mode='constant',norm='slaney',onesided=True,mel_scale='slaney')\n",
    "    hop_length300 = Config.infer_duration*Config.SR // (300-1)\n",
    "    melspec_transform300 = torchaudio.transforms.MelSpectrogram(sample_rate=Config.SR, hop_length=hop_length300, n_mels=128, f_min=50, f_max=14000, n_fft=1024, center=True, pad_mode='constant',norm='slaney',onesided=True,mel_scale='slaney')\n",
    "    melspec_transform_rev2s = torchaudio.transforms.MelSpectrogram(sample_rate=Config.SR, hop_length=320, n_mels=64, f_min=50, f_max=14000, n_fft=1024, center=True, pad_mode='constant',norm='slaney',onesided=True,mel_scale='slaney')\n",
    "    \n",
    "    db_transform = torchaudio.transforms.AmplitudeToDB(stype='power',top_db=80)\n",
    "\n",
    "    def transform_to_spec(audio,train=True):\n",
    "        \n",
    "        amin=1e-10\n",
    "        ref_value=1.0\n",
    "        db_multiplier = math.log10(max(amin, ref_value))\n",
    "        spec = melspec_transform(audio)     \n",
    "        #spec = torchaudio.functional.amplitude_to_DB(spec,multiplier=10,amin=amin,db_multiplier=db_multiplier,top_db=80)\n",
    "        spec = db_transform(spec)\n",
    "        spec256 = melspec_transform256(audio)\n",
    "        spec256 = db_transform(spec256)\n",
    "        \n",
    "        #spec224 = melspec_transform224(audio)\n",
    "        #spec224 = db_transform(spec224)\n",
    "        \n",
    "        spec300_another = melspec_transform300(audio)\n",
    "        spec300_another = db_transform(spec300_another)\n",
    "        \n",
    "        spec_rev2s = melspec_transform_rev2s(audio)\n",
    "        spec_rev2s = db_transform(spec_rev2s)\n",
    "        \n",
    "        spec384 = (spec+80)/80\n",
    "        spec256 = spec256/255\n",
    "        #spec224 = spec224/255\n",
    "        spec300_another = spec300_another/255\n",
    "        spec_rev2s = (spec_rev2s+80)/80\n",
    "        return spec384,spec256,spec300_another,spec_rev2s\n",
    "\n",
    "    \n",
    "    \n",
    "    def openvino_infer(model,data,tta):\n",
    "        outputs = model.infer(inputs=[data,tta])\n",
    "        outputs = torch.tensor(outputs[list(outputs.keys())[0]])\n",
    "        return outputs\n",
    "    \n",
    "    def openvino_infer_re(model,data):\n",
    "        outputs = model.infer(inputs=[data])\n",
    "        outputs = torch.tensor(outputs[list(outputs.keys())[0]])\n",
    "        return outputs\n",
    "    \n",
    "    def compute_deltas(specgram: torch.Tensor, win_length: int = 5, mode: str = \"replicate\") -> torch.Tensor:\n",
    "        r\"\"\"\n",
    "        Delta coefficients are used to represent the rate of change of each element in the input tensor over time. This is useful for capturing the dynamic changes in audio signals, especially in speech and audio processing tasks.    \n",
    "\n",
    "        Compute delta coefficients of a tensor, usually a spectrogram:\n",
    "\n",
    "        d(t) = summation_from_n_to_N[ n{ c(t+n) - c(t-n) } ] /  2*summation_from_n_to_N[ n^2 ]\n",
    "\n",
    "        where : d(t) is the deltas at time t i.e., delta coefficient from frame t,\n",
    "        `c_t` is the spectrogram static coeffcients at time t,\n",
    "        `N` is ``(win_length-1)//2``.\n",
    "\n",
    "        Args:\n",
    "            specgram (Tensor): Tensor of audio of dimension (..., freq, time)\n",
    "            win_length (int, optional): The window length used for computing delta (Default: ``5``)\n",
    "            mode (str, optional): Mode parameter passed to padding (Default: ``\"replicate\"``)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Tensor of deltas of dimension (..., freq, time)\n",
    "\n",
    "        Example\n",
    "            >>> specgram = torch.randn(1, 40, 1000)\n",
    "            >>> delta = compute_deltas(specgram)\n",
    "            >>> delta2 = compute_deltas(delta)\n",
    "        \"\"\"\n",
    "        device = specgram.device\n",
    "        dtype = specgram.dtype\n",
    "\n",
    "        # pack batch\n",
    "        shape = specgram.size()\n",
    "        specgram = specgram.reshape(1, -1, shape[-1])\n",
    "\n",
    "        assert win_length >= 3\n",
    "\n",
    "        n = (win_length - 1) // 2\n",
    "\n",
    "        # twice sum of integer squared\n",
    "        denom = n * (n + 1) * (2 * n + 1) / 3\n",
    "\n",
    "        specgram = torch.nn.functional.pad(specgram, (n, n), mode=mode)\n",
    "\n",
    "        kernel = torch.arange(-n, n + 1, 1, device=device, dtype=dtype).repeat(specgram.shape[1], 1, 1)\n",
    "\n",
    "        output = torch.nn.functional.conv1d(specgram, kernel, groups=specgram.shape[1]) / denom\n",
    "\n",
    "        # unpack batch\n",
    "        output = output.reshape(shape)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def make_delta(input_tensor: torch.Tensor):\n",
    "        input_tensor = input_tensor.transpose(3,2)\n",
    "        input_tensor = compute_deltas(input_tensor)\n",
    "        input_tensor = input_tensor.transpose(3,2)\n",
    "        return input_tensor\n",
    "\n",
    "\n",
    "    def image_delta(x):\n",
    "        delta_1 = make_delta(x)\n",
    "        delta_2 = make_delta(delta_1)\n",
    "        x = torch.cat([x,delta_1,delta_2], dim=1)\n",
    "        return x\n",
    "    \n",
    "    def reshp(images):\n",
    "        bs,clip_len,channel_num,mel_num,time_len = images.size()\n",
    "        images=images.reshape((bs*clip_len,channel_num,mel_num,time_len))\n",
    "        return images\n",
    "    \n",
    "    def predict(data_loader, models,re_models):   \n",
    "        predictions = []\n",
    "        pred_binary = []\n",
    "        dl_test = DataLoader(ds_test, batch_size=batch_size,num_workers = num_workers, multiprocessing_context=get_context('loky'))\n",
    "        \n",
    "        for spec384,spec256,spec300_another,spec_rev2s in dl_test:\n",
    "            spec384 = reshp(spec384)\n",
    "            spec256 = reshp(spec256)\n",
    "            spec300_another = reshp(spec300_another)\n",
    "            \n",
    "            # normalize.\n",
    "            spec300_80 = (spec300_another*255+80)/80\n",
    "            spec_rev2s = reshp(spec_rev2s)\n",
    "            \n",
    "\n",
    "            out = []\n",
    "            for i,model in enumerate(models):\n",
    "                if i==0:\n",
    "                    images2_3chan = image_delta(spec384).numpy()\n",
    "\n",
    "                    if images2_3chan.shape[0]>120:\n",
    "                        output1 = openvino_infer(model,images2_3chan[:120,:,:,:],3)\n",
    "                        output2 = openvino_infer(model,images2_3chan[120:240,:,:,:],3)\n",
    "                        outputs = torch.cat([output1,output2],dim=0)\n",
    "                    else:\n",
    "                        outputs = openvino_infer(model,images2_3chan,3)\n",
    "                elif i==1: # i==2\n",
    "                    images_3chan = image_delta(spec300_another).numpy()\n",
    "                    if images_3chan.shape[0]>120:\n",
    "                        output1 = openvino_infer(model,images_3chan[:120,:,:,:],3)\n",
    "                        output2 = openvino_infer(model,images_3chan[120:240,:,:,:],3)\n",
    "                        outputs = torch.cat([output1,output2],dim=0)\n",
    "                    else:\n",
    "                        outputs = openvino_infer(model,images_3chan,3)\n",
    "                else:\n",
    "                    image_res = spec256.numpy()\n",
    "\n",
    "                    if image_res.shape[0]>120:\n",
    "                        output1 = openvino_infer(model,image_res[:120,:,:,:],2)\n",
    "                        output2 = openvino_infer(model,image_res[120:240,:,:,:],2)\n",
    "                        outputs = torch.cat([output1,output2],dim=0)\n",
    "                    else:\n",
    "                        outputs = openvino_infer(model,image_res,2)\n",
    "\n",
    "                out.append(outputs)\n",
    "                \n",
    "\n",
    "            for i,model in enumerate(re_models):\n",
    "#                 if (i==0): # i==0\n",
    "#                     images_center_resize1 = image_delta(spec256)[:,:,:,128:384].numpy()\n",
    "#                     if images_center_resize1.shape[0]>120:\n",
    "#                         output1 = openvino_infer_re(model,images_center_resize1[:120,:,:,:])\n",
    "#                         output2 = openvino_infer_re(model,images_center_resize1[120:240,:,:,:])\n",
    "#                         outputs = torch.cat([output1,output2],dim=0)\n",
    "#                     else:\n",
    "#                         outputs = openvino_infer_re(model,images_center_resize1)\n",
    "                if (i==0): #elif (i==1):\n",
    "                    images_center_resize2 = image_delta(spec300_80)[:,:,:,150:450].numpy()\n",
    "                    if images_center_resize2.shape[0]>120:\n",
    "                        output1 = openvino_infer_re(model,images_center_resize2[:120,:,:,:])\n",
    "                        output2 = openvino_infer_re(model,images_center_resize2[120:240,:,:,:])\n",
    "                        outputs = torch.cat([output1,output2],dim=0)\n",
    "                    else:\n",
    "                        outputs = openvino_infer_re(model,images_center_resize2)\n",
    "                elif (i==1): # i==2\n",
    "                    images_re_v2s = image_delta(spec_rev2s)[:,:,:,250:750].numpy()\n",
    "                    if images_re_v2s.shape[0]>120:\n",
    "                        output1 = openvino_infer_re(model,images_re_v2s[:120,:,:,:])\n",
    "                        output2 = openvino_infer_re(model,images_re_v2s[120:240,:,:,:])\n",
    "                        outputs = torch.cat([output1,output2],dim=0)\n",
    "                    else:\n",
    "                        outputs = openvino_infer_re(model,images_re_v2s)\n",
    "#                 elif (i==3):\n",
    "#                     image_b0ns = spec256[:,:,:,128:384].numpy()\n",
    "#                     if image_b0ns.shape[0]>120:\n",
    "#                         output1 = openvino_infer_re(model,image_b0ns[:120,:,:,:])\n",
    "#                         output2 = openvino_infer_re(model,image_b0ns[120:240,:,:,:])\n",
    "#                         outputs = torch.cat([output1,output2],dim=0)\n",
    "#                     else:\n",
    "#                         outputs = openvino_infer_re(model,image_b0ns)    \n",
    "                else:\n",
    "                    outputs = model(images_center_resize3)\n",
    "    \n",
    "                out.append(outputs)\n",
    "                \n",
    "            predictions.append(out)\n",
    "        return predictions\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"Create Dataloader...\")\n",
    "\n",
    "    ds_test = BirdDatasetSED(\n",
    "        df_test, \n",
    "        sr = Config.SR,\n",
    "        duration = Config.DURATION,\n",
    "        train = False\n",
    "    )\n",
    "\n",
    "    \n",
    "    #print(\"Model Creation\")\n",
    "    models = []\n",
    "    for i,ckpt in enumerate(Config.model_ckpt):\n",
    "        #if i==0:\n",
    "        #    model = load_mdl(name,ckpt,size,sed_3chan=True)\n",
    "        #else:\n",
    "        #    model = load_mdl(name,ckpt,size)\n",
    "\n",
    "        model = core.read_model(model=ckpt)\n",
    "        model = core.compile_model(model, device_name=\"CPU\")\n",
    "        model = model.create_infer_request()\n",
    "        models.append(model)\n",
    "        \n",
    "    re_models = []\n",
    "    for i,ckpt in enumerate(Config.re_model_ckpt):\n",
    "\n",
    "        model = core.read_model(model=ckpt)\n",
    "        model = core.compile_model(model, device_name=\"CPU\")\n",
    "        model = model.create_infer_request()\n",
    "        re_models.append(model)\n",
    "\n",
    "    print(\"Running Inference..\")\n",
    "    time.sleep(sleep)\n",
    "    preds = predict(ds_test, models,re_models)   \n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b140a515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:10.475580Z",
     "iopub.status.busy": "2023-07-28T16:32:10.475110Z",
     "iopub.status.idle": "2023-07-28T16:32:10.507713Z",
     "shell.execute_reply": "2023-07-28T16:32:10.506321Z"
    },
    "papermill": {
     "duration": 0.044932,
     "end_time": "2023-07-28T16:32:10.510253",
     "exception": false,
     "start_time": "2023-07-28T16:32:10.465321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_29201</td>\n",
       "      <td>soundscape</td>\n",
       "      <td>29201</td>\n",
       "      <td>/kaggle/input/birdclef-2023/test_soundscapes/s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename        name     id  \\\n",
       "0  soundscape_29201  soundscape  29201   \n",
       "\n",
       "                                                path  \n",
       "0  /kaggle/input/birdclef-2023/test_soundscapes/s...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(\n",
    "     [(path.stem, *path.stem.split(\"_\"), path) for path in Path(Config.test_path).glob(\"*.ogg\")],\n",
    "    columns = [\"filename\", \"name\" ,\"id\", \"path\"]\n",
    ")\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "391fb253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:10.532772Z",
     "iopub.status.busy": "2023-07-28T16:32:10.531345Z",
     "iopub.status.idle": "2023-07-28T16:32:10.538358Z",
     "shell.execute_reply": "2023-07-28T16:32:10.536967Z"
    },
    "papermill": {
     "duration": 0.020062,
     "end_time": "2023-07-28T16:32:10.541256",
     "exception": false,
     "start_time": "2023-07-28T16:32:10.521194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_test = pd.concat([df_test]*200,axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d083f734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:10.562567Z",
     "iopub.status.busy": "2023-07-28T16:32:10.561138Z",
     "iopub.status.idle": "2023-07-28T16:32:10.567580Z",
     "shell.execute_reply": "2023-07-28T16:32:10.566479Z"
    },
    "papermill": {
     "duration": 0.020136,
     "end_time": "2023-07-28T16:32:10.570265",
     "exception": false,
     "start_time": "2023-07-28T16:32:10.550129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpu_num=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ab968d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:10.591062Z",
     "iopub.status.busy": "2023-07-28T16:32:10.589835Z",
     "iopub.status.idle": "2023-07-28T16:32:10.598942Z",
     "shell.execute_reply": "2023-07-28T16:32:10.597642Z"
    },
    "papermill": {
     "duration": 0.022278,
     "end_time": "2023-07-28T16:32:10.601478",
     "exception": false,
     "start_time": "2023-07-28T16:32:10.579200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_job = min([cpu_num,len(df_test)])\n",
    "split = len(df_test)//num_job\n",
    "num_job,split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51d5776f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:10.621626Z",
     "iopub.status.busy": "2023-07-28T16:32:10.621154Z",
     "iopub.status.idle": "2023-07-28T16:32:10.631685Z",
     "shell.execute_reply": "2023-07-28T16:32:10.630260Z"
    },
    "papermill": {
     "duration": 0.023947,
     "end_time": "2023-07-28T16:32:10.634306",
     "exception": false,
     "start_time": "2023-07-28T16:32:10.610359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_test = []\n",
    "df_test_left = None\n",
    "for i in range(num_job):\n",
    "    df_test_split = df_test.iloc[i*split:(i+1)*split].reset_index(drop=True)\n",
    "    dfs_test.append(df_test_split)\n",
    "    if i==num_job-1:\n",
    "        df_test_left = df_test.iloc[(i+1)*split:].reset_index(drop=True)\n",
    "len(dfs_test),len(df_test_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22b5bb45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:10.655029Z",
     "iopub.status.busy": "2023-07-28T16:32:10.653722Z",
     "iopub.status.idle": "2023-07-28T16:32:58.649251Z",
     "shell.execute_reply": "2023-07-28T16:32:58.647811Z"
    },
    "papermill": {
     "duration": 48.016881,
     "end_time": "2023-07-28T16:32:58.660159",
     "exception": false,
     "start_time": "2023-07-28T16:32:10.643278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Dataloader...\n",
      "Running Inference..\n",
      "47.98553943634033\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1=time.time()\n",
    "#results1 = joblib.Parallel(n_jobs=num_job, backend='loky')(joblib.delayed(pred)(df_test) for df_test in dfs_test)\n",
    "results1 = joblib.Parallel(n_jobs=num_job, backend='loky')(joblib.delayed(pred)(df_test,num_workers,sl,batch_size) for df_test,num_workers,sl,batch_size in zip(dfs_test,[2,2],[0,5],[2,2]))\n",
    "t2=time.time()\n",
    "print(t2-t1)\n",
    "\n",
    "# len(results1[0][0])=> 7\n",
    "# results1[0][0][0].shape => torch.Size([120, 264])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1aaeb7",
   "metadata": {
    "papermill": {
     "duration": 0.008723,
     "end_time": "2023-07-28T16:32:58.677962",
     "exception": false,
     "start_time": "2023-07-28T16:32:58.669239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4641a618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:58.698975Z",
     "iopub.status.busy": "2023-07-28T16:32:58.697967Z",
     "iopub.status.idle": "2023-07-28T16:32:58.706270Z",
     "shell.execute_reply": "2023-07-28T16:32:58.704960Z"
    },
    "papermill": {
     "duration": 0.0223,
     "end_time": "2023-07-28T16:32:58.709478",
     "exception": false,
     "start_time": "2023-07-28T16:32:58.687178",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00017595291137695312\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "results2 = []\n",
    "if len(df_test_left)>0:\n",
    "    results2 = joblib.Parallel(n_jobs=num_job, backend='loky')(joblib.delayed(pred)(df_test_left.iloc[i:i+1].reset_index(drop=True)) for i in range(len(df_test_left)))\n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fe66efb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:58.729926Z",
     "iopub.status.busy": "2023-07-28T16:32:58.729513Z",
     "iopub.status.idle": "2023-07-28T16:32:58.734476Z",
     "shell.execute_reply": "2023-07-28T16:32:58.733192Z"
    },
    "papermill": {
     "duration": 0.018237,
     "end_time": "2023-07-28T16:32:58.736818",
     "exception": false,
     "start_time": "2023-07-28T16:32:58.718581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = results1+results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13dd3192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:58.757356Z",
     "iopub.status.busy": "2023-07-28T16:32:58.756919Z",
     "iopub.status.idle": "2023-07-28T16:32:58.764587Z",
     "shell.execute_reply": "2023-07-28T16:32:58.763290Z"
    },
    "papermill": {
     "duration": 0.021099,
     "end_time": "2023-07-28T16:32:58.767208",
     "exception": false,
     "start_time": "2023-07-28T16:32:58.746109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=[]\n",
    "for r in results:\n",
    "    preds+=r\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "185ff185",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:58.788283Z",
     "iopub.status.busy": "2023-07-28T16:32:58.787400Z",
     "iopub.status.idle": "2023-07-28T16:32:58.794871Z",
     "shell.execute_reply": "2023-07-28T16:32:58.793454Z"
    },
    "papermill": {
     "duration": 0.020803,
     "end_time": "2023-07-28T16:32:58.797556",
     "exception": false,
     "start_time": "2023-07-28T16:32:58.776753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds1=[]\n",
    "preds2=[]\n",
    "preds3=[]\n",
    "preds4=[]\n",
    "preds5=[]\n",
    "preds6=[]\n",
    "preds7=[]\n",
    "for r1,r2,r3,r4 in preds: # r1,r2,r3,r4,r5,r6,r7\n",
    "    preds1.append(r1)\n",
    "    preds2.append(r2)\n",
    "    preds3.append(r3)\n",
    "    preds4.append(r4)\n",
    "#     preds5.append(r5)\n",
    "#     preds6.append(r6)\n",
    "#     preds7.append(r7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31188f63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:58.818344Z",
     "iopub.status.busy": "2023-07-28T16:32:58.817936Z",
     "iopub.status.idle": "2023-07-28T16:32:58.846142Z",
     "shell.execute_reply": "2023-07-28T16:32:58.844688Z"
    },
    "papermill": {
     "duration": 0.042064,
     "end_time": "2023-07-28T16:32:58.849201",
     "exception": false,
     "start_time": "2023-07-28T16:32:58.807137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filenames = df_test.filename.values.tolist()\n",
    "\n",
    "bird_cols = list(pd.get_dummies(df_train['primary_label']).columns)\n",
    "sub_df = pd.DataFrame(columns=['row_id']+bird_cols)\n",
    "\n",
    "# print(len(filenames[0])) => 16\n",
    "# filenames[0] => soundscape_29201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4eccb709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:58.871365Z",
     "iopub.status.busy": "2023-07-28T16:32:58.870886Z",
     "iopub.status.idle": "2023-07-28T16:32:58.891245Z",
     "shell.execute_reply": "2023-07-28T16:32:58.889722Z"
    },
    "papermill": {
     "duration": 0.034609,
     "end_time": "2023-07-28T16:32:58.894067",
     "exception": false,
     "start_time": "2023-07-28T16:32:58.859458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>abethr1</th>\n",
       "      <th>abhori1</th>\n",
       "      <th>abythr1</th>\n",
       "      <th>afbfly1</th>\n",
       "      <th>afdfly1</th>\n",
       "      <th>afecuc1</th>\n",
       "      <th>affeag1</th>\n",
       "      <th>afgfly1</th>\n",
       "      <th>afghor1</th>\n",
       "      <th>...</th>\n",
       "      <th>yebsto1</th>\n",
       "      <th>yeccan1</th>\n",
       "      <th>yefcan</th>\n",
       "      <th>yelbis1</th>\n",
       "      <th>yenspu1</th>\n",
       "      <th>yertin1</th>\n",
       "      <th>yesbar1</th>\n",
       "      <th>yespet1</th>\n",
       "      <th>yetgre1</th>\n",
       "      <th>yewgre1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_id, abethr1, abhori1, abythr1, afbfly1, afdfly1, afecuc1, affeag1, afgfly1, afghor1, afmdov1, afpfly1, afpkin1, afpwag1, afrgos1, afrgrp1, afrjac1, afrthr1, amesun2, augbuz1, bagwea1, barswa, bawhor2, bawman1, bcbeat1, beasun2, bkctch1, bkfruw1, blacra1, blacuc1, blakit1, blaplo1, blbpuf2, blcapa2, blfbus1, blhgon1, blhher1, blksaw1, blnmou1, blnwea1, bltapa1, bltbar1, bltori1, blwlap1, brcale1, brcsta1, brctch1, brcwea1, brican1, brobab1, broman1, brosun1, brrwhe3, brtcha1, brubru1, brwwar1, bswdov1, btweye2, bubwar2, butapa1, cabgre1, carcha1, carwoo1, categr, ccbeat1, chespa1, chewea1, chibat1, chtapa3, chucis1, cibwar1, cohmar1, colsun2, combul2, combuz1, comsan, crefra2, crheag1, crohor1, darbar1, darter3, didcuc1, dotbar1, dutdov1, easmog1, eaywag1, edcsun3, egygoo, equaka1, eswdov1, eubeat1, fatrav1, fatwid1, fislov1, fotdro5, gabgos2, gargan, gbesta1, gnbcam2, gnhsun1, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 265 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a860214e",
   "metadata": {
    "papermill": {
     "duration": 0.009256,
     "end_time": "2023-07-28T16:32:58.913400",
     "exception": false,
     "start_time": "2023-07-28T16:32:58.904144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b556ae9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:58.934328Z",
     "iopub.status.busy": "2023-07-28T16:32:58.933872Z",
     "iopub.status.idle": "2023-07-28T16:32:58.940276Z",
     "shell.execute_reply": "2023-07-28T16:32:58.939014Z"
    },
    "papermill": {
     "duration": 0.019876,
     "end_time": "2023-07-28T16:32:58.942729",
     "exception": false,
     "start_time": "2023-07-28T16:32:58.922853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_row_ids(file):\n",
    "    num_rows = 120\n",
    "    row_ids = np.array([f'{file}_{(i+1)*5}' for i in range(num_rows)])\n",
    "    return row_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cacce11f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:58.963594Z",
     "iopub.status.busy": "2023-07-28T16:32:58.963159Z",
     "iopub.status.idle": "2023-07-28T16:32:59.400748Z",
     "shell.execute_reply": "2023-07-28T16:32:59.398857Z"
    },
    "papermill": {
     "duration": 0.452534,
     "end_time": "2023-07-28T16:32:59.404697",
     "exception": false,
     "start_time": "2023-07-28T16:32:58.952163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#row_ids = joblib.Parallel(n_jobs=4, backend='loky')(joblib.delayed(make_row_ids)(preds[i],file) for i, file in enumerate(filenames))\n",
    "row_ids = joblib.Parallel(n_jobs=4, backend='loky')(joblib.delayed(make_row_ids)(file) for i, file in enumerate(filenames))\n",
    "row_ids = np.concatenate(row_ids,axis=0)\n",
    "#data = np.concatenate(preds,axis=0)\n",
    "data1 = torch.cat(preds1,dim=0).logit()\n",
    "data2 = torch.cat(preds2,dim=0).logit()\n",
    "# data3 = torch.cat(preds3,dim=0).logit()\n",
    "data4 = torch.cat(preds3,dim=0) # preds4\n",
    "data5 = torch.cat(preds4,dim=0) # preds5\n",
    "# data6 = torch.cat(preds6,dim=0)\n",
    "# data7 = torch.cat(preds7,dim=0)\n",
    "#data_binary = np.concatenate(preds_binary,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "989f68c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:59.439585Z",
     "iopub.status.busy": "2023-07-28T16:32:59.438977Z",
     "iopub.status.idle": "2023-07-28T16:32:59.447196Z",
     "shell.execute_reply": "2023-07-28T16:32:59.445998Z"
    },
    "papermill": {
     "duration": 0.029459,
     "end_time": "2023-07-28T16:32:59.450269",
     "exception": false,
     "start_time": "2023-07-28T16:32:59.420810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensemble(sed_pred,sed_pred2,re_pred,re_pred2,):    \n",
    "    #sed_pred[:,:] = 0.25*sed_pred[:,:] + 0.1*sed_pred2 + 0.21*sed_pred3 + 0.1*re_pred[:,:] + 0.15*re_pred2[:,:] + 0.15*re_pred3[:,:] + 0.04*re_pred4[:,:]    \n",
    "    sed_pred[:,:] = 0.30*sed_pred[:,:] + 0.26*sed_pred2 + 0.22*re_pred[:,:] + 0.22*re_pred2[:,:] \n",
    "    return sed_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ae44a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:59.471604Z",
     "iopub.status.busy": "2023-07-28T16:32:59.471150Z",
     "iopub.status.idle": "2023-07-28T16:32:59.478516Z",
     "shell.execute_reply": "2023-07-28T16:32:59.477584Z"
    },
    "papermill": {
     "duration": 0.021057,
     "end_time": "2023-07-28T16:32:59.480945",
     "exception": false,
     "start_time": "2023-07-28T16:32:59.459888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = ensemble(data1,data2,data4,data5).sigmoid().numpy()\n",
    "#data = ensemble(data1,data2,data3,data4,data5,data6,data7).sigmoid().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35aae8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:59.502482Z",
     "iopub.status.busy": "2023-07-28T16:32:59.501593Z",
     "iopub.status.idle": "2023-07-28T16:32:59.618029Z",
     "shell.execute_reply": "2023-07-28T16:32:59.616425Z"
    },
    "papermill": {
     "duration": 0.130538,
     "end_time": "2023-07-28T16:32:59.620899",
     "exception": false,
     "start_time": "2023-07-28T16:32:59.490361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>abethr1</th>\n",
       "      <th>abhori1</th>\n",
       "      <th>abythr1</th>\n",
       "      <th>afbfly1</th>\n",
       "      <th>afdfly1</th>\n",
       "      <th>afecuc1</th>\n",
       "      <th>affeag1</th>\n",
       "      <th>afgfly1</th>\n",
       "      <th>afghor1</th>\n",
       "      <th>...</th>\n",
       "      <th>yebsto1</th>\n",
       "      <th>yeccan1</th>\n",
       "      <th>yefcan</th>\n",
       "      <th>yelbis1</th>\n",
       "      <th>yenspu1</th>\n",
       "      <th>yertin1</th>\n",
       "      <th>yesbar1</th>\n",
       "      <th>yespet1</th>\n",
       "      <th>yetgre1</th>\n",
       "      <th>yewgre1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_29201_5</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.017291</td>\n",
       "      <td>0.008345</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.007772</td>\n",
       "      <td>0.010265</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.017059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007633</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>0.020315</td>\n",
       "      <td>0.009698</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>0.012563</td>\n",
       "      <td>0.008322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_29201_10</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>0.020401</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.014197</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>0.020903</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>0.009661</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.005455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_29201_15</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.008847</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>0.003942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_29201_20</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.006437</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.005932</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.013417</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.012656</td>\n",
       "      <td>0.009403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_29201_25</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.010764</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>0.014156</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.016504</td>\n",
       "      <td>0.011559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>soundscape_29201_580</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.006377</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.008154</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>0.006646</td>\n",
       "      <td>0.011336</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.008036</td>\n",
       "      <td>0.006785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>soundscape_29201_585</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.008894</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.009101</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>0.006612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.003936</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>0.008450</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.019774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>soundscape_29201_590</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.010344</td>\n",
       "      <td>0.007884</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.005598</td>\n",
       "      <td>0.004080</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>0.010385</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.010252</td>\n",
       "      <td>0.012106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>soundscape_29201_595</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.007219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.004437</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.015740</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>0.006617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>soundscape_29201_600</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.007361</td>\n",
       "      <td>0.012747</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.019421</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.013148</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>0.015935</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.012577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   row_id   abethr1   abhori1   abythr1   afbfly1   afdfly1  \\\n",
       "0      soundscape_29201_5  0.014188  0.017291  0.008345  0.005549  0.001573   \n",
       "1     soundscape_29201_10  0.005832  0.020401  0.004180  0.014197  0.001103   \n",
       "2     soundscape_29201_15  0.001369  0.008218  0.003103  0.003628  0.000296   \n",
       "3     soundscape_29201_20  0.001488  0.004240  0.002831  0.006437  0.000961   \n",
       "4     soundscape_29201_25  0.002133  0.006078  0.004749  0.010764  0.001704   \n",
       "..                    ...       ...       ...       ...       ...       ...   \n",
       "115  soundscape_29201_580  0.002185  0.004824  0.002392  0.006377  0.000992   \n",
       "116  soundscape_29201_585  0.004027  0.008109  0.004103  0.008894  0.001628   \n",
       "117  soundscape_29201_590  0.003203  0.007900  0.003876  0.008248  0.001363   \n",
       "118  soundscape_29201_595  0.002954  0.006444  0.002408  0.007100  0.003177   \n",
       "119  soundscape_29201_600  0.009505  0.010616  0.007361  0.012747  0.002022   \n",
       "\n",
       "      afecuc1   affeag1   afgfly1   afghor1  ...   yebsto1   yeccan1  \\\n",
       "0    0.007772  0.010265  0.004184  0.017059  ...  0.007633  0.004172   \n",
       "1    0.005842  0.008506  0.002502  0.007123  ...  0.004625  0.004750   \n",
       "2    0.003441  0.003691  0.002009  0.003930  ...  0.001767  0.003608   \n",
       "3    0.005932  0.002192  0.002851  0.005197  ...  0.002449  0.009530   \n",
       "4    0.005689  0.002865  0.004310  0.005347  ...  0.003714  0.007644   \n",
       "..        ...       ...       ...       ...  ...       ...       ...   \n",
       "115  0.005143  0.003197  0.003276  0.005457  ...  0.002919  0.008154   \n",
       "116  0.009101  0.010256  0.004412  0.006612  ...  0.005438  0.004790   \n",
       "117  0.010344  0.007884  0.004734  0.007378  ...  0.003453  0.005598   \n",
       "118  0.005454  0.002680  0.004103  0.007219  ...  0.001208  0.007071   \n",
       "119  0.007651  0.019421  0.004556  0.006191  ...  0.002610  0.008207   \n",
       "\n",
       "       yefcan   yelbis1   yenspu1   yertin1   yesbar1   yespet1   yetgre1  \\\n",
       "0    0.003794  0.004810  0.020315  0.009698  0.004881  0.005030  0.012563   \n",
       "1    0.015958  0.020903  0.009291  0.009661  0.003252  0.003427  0.004097   \n",
       "2    0.003934  0.007100  0.003789  0.004342  0.001253  0.008847  0.008734   \n",
       "3    0.002924  0.001659  0.006797  0.013417  0.002347  0.005050  0.012656   \n",
       "4    0.003570  0.003821  0.010008  0.014156  0.002872  0.006988  0.016504   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "115  0.003638  0.002331  0.006646  0.011336  0.003085  0.005180  0.008036   \n",
       "116  0.003975  0.003936  0.008761  0.015217  0.008450  0.007903  0.005666   \n",
       "117  0.004080  0.003185  0.006899  0.010385  0.005455  0.006022  0.010252   \n",
       "118  0.004708  0.004437  0.004535  0.015740  0.002768  0.003433  0.010768   \n",
       "119  0.013148  0.003986  0.009331  0.015935  0.005303  0.005740  0.020361   \n",
       "\n",
       "      yewgre1  \n",
       "0    0.008322  \n",
       "1    0.005455  \n",
       "2    0.003942  \n",
       "3    0.009403  \n",
       "4    0.011559  \n",
       "..        ...  \n",
       "115  0.006785  \n",
       "116  0.019774  \n",
       "117  0.012106  \n",
       "118  0.006617  \n",
       "119  0.012577  \n",
       "\n",
       "[120 rows x 265 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df['row_id'] = row_ids\n",
    "sub_df[bird_cols] = data\n",
    "#sub_df = pd.concat(dfs).reset_index(drop=True)\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa0fd120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:32:59.643086Z",
     "iopub.status.busy": "2023-07-28T16:32:59.642684Z",
     "iopub.status.idle": "2023-07-28T16:32:59.705280Z",
     "shell.execute_reply": "2023-07-28T16:32:59.703519Z"
    },
    "papermill": {
     "duration": 0.078256,
     "end_time": "2023-07-28T16:32:59.709297",
     "exception": false,
     "start_time": "2023-07-28T16:32:59.631041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39cf04",
   "metadata": {
    "papermill": {
     "duration": 0.012957,
     "end_time": "2023-07-28T16:32:59.733602",
     "exception": false,
     "start_time": "2023-07-28T16:32:59.720645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27b9ad",
   "metadata": {
    "papermill": {
     "duration": 0.013257,
     "end_time": "2023-07-28T16:32:59.761214",
     "exception": false,
     "start_time": "2023-07-28T16:32:59.747957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437bc7ce",
   "metadata": {
    "papermill": {
     "duration": 0.00969,
     "end_time": "2023-07-28T16:32:59.781478",
     "exception": false,
     "start_time": "2023-07-28T16:32:59.771788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 88.525114,
   "end_time": "2023-07-28T16:33:02.418151",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-28T16:31:33.893037",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
